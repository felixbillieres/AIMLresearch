# Resources — Adversarial ML & LLM Security

## Frameworks
| Resource | Link | Status |
|----------|------|--------|
| OWASP Top 10 for LLM Applications | https://genai.owasp.org | ⬜ |
| MITRE ATLAS | https://atlas.mitre.org | ⬜ |

## Tools
| Tool | Purpose | Link | Status |
|------|---------|------|--------|
| Garak (NVIDIA) | LLM vulnerability scanner | https://github.com/NVIDIA/garak | ⬜ |
| PyRIT (Microsoft) | AI red teaming framework | https://github.com/Azure/PyRIT | ⬜ |
| Promptmap | Prompt injection testing | https://github.com/utkusen/promptmap | ⬜ |

## Papers
| # | Paper | Link | Read? |
|---|-------|------|-------|
| 1 | Jailbroken: How Does LLM Safety Training Fail? | https://arxiv.org/abs/2307.02483 | ⬜ |
| 2 | Universal Adversarial Attacks on Aligned LLMs (GCG) | https://arxiv.org/abs/2307.15043 | ⬜ |
| 3 | Indirect Prompt Injection (Greshake) | https://arxiv.org/abs/2302.12173 | ⬜ |
| 4 | HackAPrompt (Schulhoff) | https://arxiv.org/abs/2311.16119 | ⬜ |
| 5 | Sleeper Agents (Anthropic) | https://arxiv.org/abs/2401.05566 | ⬜ |
| 6 | Scalable Extraction of Training Data (Carlini) | https://arxiv.org/abs/2311.17035 | ⬜ |
| 7 | LLM Agents can Autonomously Hack Websites (Fang) | https://arxiv.org/abs/2402.06664 | ⬜ |
| 8 | Adversarial Attacks on LLMs (survey) | https://arxiv.org/abs/2308.07308 | ⬜ |

## Talks & Conferences
| Talk | Venue | Link |
|------|-------|------|
| DEF CON AI Village recordings | DEF CON | https://aivillage.org/ |
| SaTML conference | IEEE | https://satml.org/ |
